{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/insurance_claims.csv\")","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"_uuid":"9ddfe11136bbac83eb624a88217588e38d7eef5f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.describe()","metadata":{"_uuid":"0817ac5423a3a93d3b931238077b8660dd168ed6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping columns \ndata.drop('_c39',axis=1,inplace=True)","metadata":{"_uuid":"b80b6b8377fbe0c8828adeaedf27ffbc97c57af6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking missing values\n# Function to calculate missing values by column# Funct \ndef missing_values_table(df):\n        # Total missing values\n        mis_val = df.isnull().sum()\n        \n        # Percentage of missing values\n        mis_val_percent = 100 * df.isnull().sum() / len(df)\n        \n        # Make a table with the results\n        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n        \n        # Rename the columns\n        mis_val_table_ren_columns = mis_val_table.rename(\n        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n        \n        # Sort the table by percentage of missing descending\n        mis_val_table_ren_columns = mis_val_table_ren_columns[\n            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n        \n        # Print some summary information\n        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n              \" columns that have missing values.\")\n        \n        # Return the dataframe with missing information\n        return mis_val_table_ren_columns","metadata":{"_uuid":"507906134a743768de44f92bcc8ec6bc4992cedd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Missing values statistics\nmissing_values = missing_values_table(data)\nmissing_values","metadata":{"_uuid":"99a886e71d42ba518660f9bf83d2c50969a18fe7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets do Lable enconding coding to make more features \n\nle = LabelEncoder()\nle_count = 0\n\n# Iterate through the columns\nfor col in data:\n    if data[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        if len(list(data[col].unique())) <= 2:\n            # Train on the training data\n            le.fit(data[col])\n            # Transform both training and testing data\n            data[col] = le.transform(data[col])\n            \n            \n            # Keep track of how many columns were label encoded\n            le_count += 1\n            \nprint('%d columns were label encoded.' % le_count)","metadata":{"_uuid":"7cf970ab6344ce466511a28a2f2bdaf833f2aabd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data = pd.get_dummies(data)\n#print('Training Features shape: ', data.shape)\nsns.set(style=\"white\")\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\nsns.heatmap(data.corr(), cmap=cmap, vmax=.3, center=0,annot=True,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","metadata":{"_uuid":"460c48da39c2b5a2a24059f60765bfd6a1dc32c4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colum_name =[]\nunique_value=[]\n# Iterate through the columns\nfor col in data:\n    if data[col].dtype == 'object':\n        # If 2 or fewer unique categories\n        colum_name.append(str(col)) \n        unique_value.append(data[col].nunique())\ntable= pd.DataFrame()\ntable['Col_name'] = colum_name\ntable['Value']= unique_value\n            \ntable=table.sort_values('Value',ascending=False)\ntable","metadata":{"_uuid":"6da2ee7f68bb7fc5917d1c44b8dc94e696d641c3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# droping columns based on above result\ndata.drop(['incident_location','policy_bind_date','incident_date','auto_model','insured_occupation','policy_number'],axis=1,inplace=True)","metadata":{"_uuid":"f75f3dffafa6ebb2877b384cd9f0e7a88cb69e33","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(20, 20))\nsns.countplot(x='insured_hobbies',hue='fraud_reported',data=data)","metadata":{"_uuid":"ae0d0f0949b1fcae97545e3100c53c279472b7f6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create additional 'other' column if Insured hobbies are not chess and cross fit.","metadata":{"_uuid":"74e1aa759f8de158ae9676387507ddd48c7b6555"}},{"cell_type":"code","source":"data['insured_hobbies']=data['insured_hobbies'].apply(lambda x :'Other' if x!='chess' and x!='cross-fit' else x)","metadata":{"_uuid":"f9e78b449baa6c2c65a61a8f3075da8342ee958b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(20, 20))\nsns.countplot(x='auto_make',hue='fraud_reported',data=data)","metadata":{"_uuid":"b8fe887887006f6e116605772859afbb8def89b4","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['insured_hobbies'].unique()","metadata":{"_uuid":"e5f9b241216de0b24d3d5ec69947bf4dfdf09f09","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.get_dummies(data)\nprint('Training Features shape: ', data.shape)","metadata":{"_uuid":"ae25bf2f756e84507516d8e3725da585a150eaa2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets check if Data is balanced data or not?\n\n* Looking at below graph , the data looks imbalance.","metadata":{"_uuid":"c2a50fdf88df46bd449eade56de1a55846fd8cec"}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(10, 10))\nsns.countplot(x='fraud_reported',data=data)","metadata":{"_uuid":"22692e8fda71baae4aa4c2ef9a6220844c7d317f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#f, ax = plt.subplots(figsize=(20, 20))\ncorr= data.corr()\ny=data['fraud_reported']\nX= data.drop('fraud_reported',axis=1)","metadata":{"_uuid":"95bf32f2a51174fee77fa05745b3ee3ac4171972","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"153f72191c62896ac19bddc524c774ab6f762df9","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","metadata":{"_uuid":"8f2d6afba24ef5b6a669ba2a6417930a3c02a951","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef lgb_f1_score(y_hat, data):\n    y_true = data.get_label()\n    y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n    return 'f1', f1_score(y_true, y_hat), True","metadata":{"_uuid":"4ccb15194528831ac17603e4b82da9509dbc8447","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_lgb(X_train, X_test, y_train, y_test, test_df):\n    params = {\n        \"objective\" : \"binary\",\n       \"n_estimators\":1000,\n       \"reg_alpha\" : 0.5,\n       \"reg_lambda\":0.5,\n       \"n_jobs\":-1,\n       \"colsample_bytree\":.8,\n       \"min_child_weight\":8,\n       \"subsample\":0.8715623,\n       \"min_data_in_leaf\":30,\n       \"nthread\":4,\n       \"metric\" : \"f1\",\n       \"num_leaves\" : 10,\n       \"learning_rate\" : 0.01,\n       \"verbosity\" : -1,\n       \"seed\": 60,\n       \"max_bin\":60,\n       'max_depth':3,\n       'min_gain_to_split':.0222415,\n       'scale_pos_weight':1.4,\n        'bagging_fraction':0.8\n    }\n    \n    lgtrain = lgb.Dataset(X_train, label=y_train)\n    lgval = lgb.Dataset(X_test, label=y_test)\n    evals_result = {}\n    model = lgb.train(params, lgtrain, 10000, \n                      valid_sets=[lgtrain, lgval], \n                      early_stopping_rounds=100, \n                      verbose_eval=100, \n                      evals_result=evals_result,feval=lgb_f1_score)\n    \n    pred_test_y = model.predict(test_df, num_iteration=model.best_iteration)\n    return pred_test_y, model, evals_result","metadata":{"_uuid":"7b37db7a99c75a7051474f660e412c3c14b36adf","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test, model, evals_result = run_lgb(X_train, X_test, y_train, y_test, X_test)\nprint(\"LightGBM Training Completed...\")","metadata":{"_uuid":"e72255661c2d0ebc65022f352854d6f2f3c07385","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score","metadata":{"_uuid":"564bc72430d866faec8a6701bd64a10e0f773a12","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_auc_score(y_test,pred_test)","metadata":{"_uuid":"89db3b80ed1a22fac2a1e817218c41749248cd8e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfpr, tpr, threshold = metrics.roc_curve(y_test, pred_test)\nroc_auc = metrics.auc(fpr, tpr)\nf, ax = plt.subplots(figsize=(10, 10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","metadata":{"_uuid":"5909b97fb9f9d3914cdecf09409b4424d1fb3eb2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Plot feature importances...')\nax = lgb.plot_importance(model, max_num_features=10)\nplt.show()","metadata":{"_uuid":"a9561981cfa849aaff5be51976271f5e1fc26a73","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"7493a5dff7983ee75d42ed894335cae210429e8b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"_uuid":"4c766a519d2fbb1ef6350badc1bd49ebb4e6b201","trusted":true},"execution_count":null,"outputs":[]}]}